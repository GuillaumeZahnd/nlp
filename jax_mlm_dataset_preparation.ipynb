{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c693215-2e75-4457-8dd7-6b1c4df92821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax import random\n",
    "main_rng = random.PRNGKey(421)\n",
    "\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b5e8407-42af-45a0-b55b-9701c35b89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax_mlm_helpers import apply_random_masking\n",
    "from jax_mlm_helpers import pad_and_crop_to_maximum_length\n",
    "from utils_display import pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bad624c-d520-4147-a74f-65e9155b12a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8315d9-a7b4-4e45-b933-1ae9e9b4bfb1",
   "metadata": {},
   "source": [
    "# Example text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ad7ed0-fd51-4133-9316-e5b153cd797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I asked him what he was doing with a basilisk and he said that was his business. Now completely overwhelmed by curiosity, I said that these days, with all the deaths, there could be no more secret matters, and I would tell William. Then Salvatore ardently begged me to remain silent, opened the bundle, and showed me a black cat. He drew me closer and, with an obscene smile, said that he didn’t  want the cellarer, who was powerful, or me, young and handsome, to enjoy the love of the village girls any more, when he couldn’t because he was ugly and a poor wretch. But he knew a prodigious spell that would make every woman succumb to love. You had to kill a black cat and dig out its eyes, then put them in two eggs of a black hen, one eye in one egg, one eye in the other (and he showed me two eggs that he swore he had taken from appropriate hens). Then you had to let the eggs rot in a pile of horse dung (and he had one ready in a corner of the vegetable garden where nobody ever went), and there a little devil would be born from each egg, and would then be at your service, procuring for you all the delights of this world. But, alas, he told me, for the magic spell to work, the woman whose love he wanted had to spit on the eggs before they were buried in the dung, and that problem tormented him, because he would have to have the woman in question at hand that night, and make her perform the ritual without knowing its purpose.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b991e851-e1ce-47ae-9338-af86461c12b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I asked him what he was doing with a basilisk and he said that was his business.\n",
      "Now completely overwhelmed by curiosity, I said that these days, with all the deaths, there could be no more secret matters, and I would tell William.\n",
      "Then Salvatore ardently begged me to remain silent, opened the bundle, and showed me a black cat.\n",
      "He drew me closer and, with an obscene smile, said that he didn’t  want the cellarer, who was powerful, or me, young and handsome, to enjoy the love of the village girls any more, when he couldn’t because he was ugly and a poor wretch.\n",
      "But he knew a prodigious spell that would make every woman succumb to love.\n",
      "You had to kill a black cat and dig out its eyes, then put them in two eggs of a black hen, one eye in one egg, one eye in the other (and he showed me two eggs that he swore he had taken from appropriate hens).\n",
      "Then you had to let the eggs rot in a pile of horse dung (and he had one ready in a corner of the vegetable garden where nobody ever went), and there a little devil would be born from each egg, and would then be at your service, procuring for you all the delights of this world.\n",
      "But, alas, he told me, for the magic spell to work, the woman whose love he wanted had to spit on the eggs before they were buried in the dung, and that problem tormented him, because he would have to have the woman in question at hand that night, and make her perform the ritual without knowing its purpose.\n"
     ]
    }
   ],
   "source": [
    "sentences = [i for i in nlp(text).sents]\n",
    "for s in sentences:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1fbc7c2-1d3c-4bd5-9e53-e651bd3ba4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(texts, max_vocab=10000, min_freq=1):\n",
    "\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    word_counter = Counter()\n",
    "    for doc in nlp.pipe(texts):\n",
    "        for word in doc:\n",
    "            word_counter[word.lower_] += 1\n",
    "\n",
    "    dico_word2index = {}\n",
    "    dico_index2word = {}\n",
    "    \n",
    "    special_tokens = ['[MASK]', '[PAD]', '[UNK]']\n",
    "    for token in special_tokens:\n",
    "        index = len(dico_word2index)\n",
    "        dico_word2index[token] = index\n",
    "        dico_index2word[index] = token\n",
    "    \n",
    "    for word, count in word_counter.most_common():\n",
    "        if count < min_freq: break\n",
    "        if len(dico_word2index) >= max_vocab: break\n",
    "        index = len(dico_word2index)\n",
    "        dico_word2index[word] = index\n",
    "        dico_index2word[index] = word\n",
    "        \n",
    "    return dico_word2index, dico_index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acecb7c7-820d-4d4a-bdd2-e4c9bb399fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_word_tokenization(text) -> List[str]:\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    doc = nlp(text)\n",
    "    word_tokens = [str(w).lower() for w in doc]\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c85fec4-b9e8-4587-bf1c-49cb1160a68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'asked', 'him', 'what', 'he', 'was', 'doing', 'with', 'a', 'basilisk', 'and', 'he', 'said', 'that', 'was', 'his', 'business', '.', 'now', 'completely', 'overwhelmed', 'by', 'curiosity', ',', 'i', 'said', 'that', 'these', 'days', ',', 'with', 'all', 'the', 'deaths', ',', 'there', 'could', 'be', 'no', 'more', 'secret', 'matters', ',', 'and', 'i', 'would', 'tell', 'william', '.', 'then', 'salvatore', 'ardently', 'begged', 'me', 'to', 'remain', 'silent', ',', 'opened', 'the', 'bundle', ',', 'and', 'showed', 'me', 'a', 'black', 'cat', '.', 'he', 'drew', 'me', 'closer', 'and', ',', 'with', 'an', 'obscene', 'smile', ',', 'said', 'that', 'he', 'did', 'n’t', ' ', 'want', 'the', 'cellarer', ',', 'who', 'was', 'powerful', ',', 'or', 'me', ',', 'young', 'and', 'handsome', ',', 'to', 'enjoy', 'the', 'love', 'of', 'the', 'village', 'girls', 'any', 'more', ',', 'when', 'he', 'could', 'n’t', 'because', 'he', 'was', 'ugly', 'and', 'a', 'poor', 'wretch', '.', 'but', 'he', 'knew', 'a', 'prodigious', 'spell', 'that', 'would', 'make', 'every', 'woman', 'succumb', 'to', 'love', '.', 'you', 'had', 'to', 'kill', 'a', 'black', 'cat', 'and', 'dig', 'out', 'its', 'eyes', ',', 'then', 'put', 'them', 'in', 'two', 'eggs', 'of', 'a', 'black', 'hen', ',', 'one', 'eye', 'in', 'one', 'egg', ',', 'one', 'eye', 'in', 'the', 'other', '(', 'and', 'he', 'showed', 'me', 'two', 'eggs', 'that', 'he', 'swore', 'he', 'had', 'taken', 'from', 'appropriate', 'hens', ')', '.', 'then', 'you', 'had', 'to', 'let', 'the', 'eggs', 'rot', 'in', 'a', 'pile', 'of', 'horse', 'dung', '(', 'and', 'he', 'had', 'one', 'ready', 'in', 'a', 'corner', 'of', 'the', 'vegetable', 'garden', 'where', 'nobody', 'ever', 'went', ')', ',', 'and', 'there', 'a', 'little', 'devil', 'would', 'be', 'born', 'from', 'each', 'egg', ',', 'and', 'would', 'then', 'be', 'at', 'your', 'service', ',', 'procuring', 'for', 'you', 'all', 'the', 'delights', 'of', 'this', 'world', '.', 'but', ',', 'alas', ',', 'he', 'told', 'me', ',', 'for', 'the', 'magic', 'spell', 'to', 'work', ',', 'the', 'woman', 'whose', 'love', 'he', 'wanted', 'had', 'to', 'spit', 'on', 'the', 'eggs', 'before', 'they', 'were', 'buried', 'in', 'the', 'dung', ',', 'and', 'that', 'problem', 'tormented', 'him', ',', 'because', 'he', 'would', 'have', 'to', 'have', 'the', 'woman', 'in', 'question', 'at', 'hand', 'that', 'night', ',', 'and', 'make', 'her', 'perform', 'the', 'ritual', 'without', 'knowing', 'its', 'purpose', '.']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "my_tokens = apply_word_tokenization(text=doc)\n",
    "print(my_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e10f45-ca37-48ce-97f1-eee56e223eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[MASK]': 0, '[PAD]': 1, '[UNK]': 2, ',': 3, 'the': 4, 'he': 5, 'and': 6, 'a': 7, '.': 8, 'to': 9, 'that': 10, 'in': 11, 'me': 12, 'would': 13, 'of': 14, 'had': 15, 'was': 16, 'then': 17, 'eggs': 18, 'one': 19, 'i': 20, 'with': 21, 'said': 22, 'be': 23, 'black': 24, 'love': 25, 'woman': 26, 'you': 27, 'him': 28, 'all': 29, 'there': 30, 'could': 31, 'more': 32, 'showed': 33, 'cat': 34, 'n’t': 35, 'because': 36, 'but': 37, 'spell': 38, 'make': 39, 'its': 40, 'two': 41, 'eye': 42, 'egg': 43, '(': 44, 'from': 45, ')': 46, 'dung': 47, 'at': 48, 'for': 49, 'have': 50, 'asked': 51, 'what': 52, 'doing': 53, 'basilisk': 54, 'his': 55, 'business': 56, 'now': 57, 'completely': 58, 'overwhelmed': 59, 'by': 60, 'curiosity': 61, 'these': 62, 'days': 63, 'deaths': 64, 'no': 65, 'secret': 66, 'matters': 67, 'tell': 68, 'william': 69, 'salvatore': 70, 'ardently': 71, 'begged': 72, 'remain': 73, 'silent': 74, 'opened': 75, 'bundle': 76, 'drew': 77, 'closer': 78, 'an': 79, 'obscene': 80, 'smile': 81, 'did': 82, ' ': 83, 'want': 84, 'cellarer': 85, 'who': 86, 'powerful': 87, 'or': 88, 'young': 89, 'handsome': 90, 'enjoy': 91, 'village': 92, 'girls': 93, 'any': 94, 'when': 95, 'ugly': 96, 'poor': 97, 'wretch': 98, 'knew': 99, 'prodigious': 100, 'every': 101, 'succumb': 102, 'kill': 103, 'dig': 104, 'out': 105, 'eyes': 106, 'put': 107, 'them': 108, 'hen': 109, 'other': 110, 'swore': 111, 'taken': 112, 'appropriate': 113, 'hens': 114, 'let': 115, 'rot': 116, 'pile': 117, 'horse': 118, 'ready': 119, 'corner': 120, 'vegetable': 121, 'garden': 122, 'where': 123, 'nobody': 124, 'ever': 125, 'went': 126, 'little': 127, 'devil': 128, 'born': 129, 'each': 130, 'your': 131, 'service': 132, 'procuring': 133, 'delights': 134, 'this': 135, 'world': 136, 'alas': 137, 'told': 138, 'magic': 139, 'work': 140, 'whose': 141, 'wanted': 142, 'spit': 143, 'on': 144, 'before': 145, 'they': 146, 'were': 147, 'buried': 148, 'problem': 149, 'tormented': 150, 'question': 151, 'hand': 152, 'night': 153, 'her': 154, 'perform': 155, 'ritual': 156, 'without': 157, 'knowing': 158, 'purpose': 159}\n"
     ]
    }
   ],
   "source": [
    "dico_word2index, dico_index2wordd = build_vocabulary(texts=my_tokens)\n",
    "print(dico_word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ad032c-0d8c-4957-867c-2beb95234833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mInput sentence\u001b[0m: I asked him what he was doing with a basilisk and he said that was his business.\n",
      "\u001b[34mWord tokens\u001b[0m: ['i', 'asked', 'him', 'what', 'he', 'was', 'doing', 'with', 'a', 'basilisk', 'and', 'he', 'said', 'that', 'was', 'his', 'business', '.']\n",
      "\u001b[34mInput indices\u001b[0m: [20, 51, 28, 52, 5, 16, 53, 21, 7, 54, 6, 5, 22, 10, 16, 55, 56, 8]\n"
     ]
    }
   ],
   "source": [
    "input_sentence = sentences[0]\n",
    "word_tokens = apply_word_tokenization(text=str(input_sentence))\n",
    "input_indices = [dico_word2index.get(w, '[UNK]') for w in word_tokens]\n",
    "\n",
    "pc(\"Input sentence\", input_sentence)\n",
    "pc(\"Word tokens\", word_tokens)\n",
    "pc(\"Input indices\", input_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475e9cbb-5f1e-4312-86d9-4e5770d1d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "masking_probability = 0.15\n",
    "label_for_unmasked_values = -100\n",
    "maximum_sequence_length = 25\n",
    "mask_index = dico_word2index[\"[MASK]\"]\n",
    "pad_index = dico_word2index[\"[PAD]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "719ffb50-1049-4b29-8b86-60851c9b62c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before padding / cropping\n",
      "\u001b[34mInput indices\u001b[0m: [20 51 28 52  5 16 53 21  7 54  6  5 22 10 16 55 56  8]\n",
      "\u001b[34mMask\u001b[0m: [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[34mMasked indices\u001b[0m: [ 0 51  0 52  5 16 53 21  7 54  6  5 22 10 16  0 56  8]\n",
      "\u001b[34mLabels\u001b[0m: [  20 -100   28 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100   55 -100 -100]\n"
     ]
    }
   ],
   "source": [
    "input_indices, mask, masked_indices, labels = apply_random_masking(                                                                                              \n",
    "    input_indices=input_indices,                                                                                                 \n",
    "    index_for_masked_values=mask_index,\n",
    "    label_for_unmasked_values=label_for_unmasked_values,                                                                                 \n",
    "     masking_probability=masking_probability)\n",
    "\n",
    "print(\"Before padding / cropping\")\n",
    "pc(\"Input indices\", input_indices)\n",
    "pc(\"Mask\", mask)\n",
    "pc(\"Masked indices\", masked_indices)\n",
    "pc(\"Labels\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade41242-8bd7-4daf-85e4-00b6652de76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After padding / cropping\n",
      "\u001b[34mInput indices\u001b[0m: [20 51 28 52  5 16 53 21  7 54  6  5 22 10 16 55 56  8  1  1  1  1  1  1\n",
      "  1]\n",
      "\u001b[34mMask\u001b[0m: [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1]\n",
      "\u001b[34mMasked indices\u001b[0m: [ 0 51  0 52  5 16 53 21  7 54  6  5 22 10 16  0 56  8  1  1  1  1  1  1\n",
      "  1]\n",
      "\u001b[34mLabels\u001b[0m: [  20 -100   28 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100   55 -100 -100 -100 -100 -100 -100 -100 -100 -100]\n"
     ]
    }
   ],
   "source": [
    "input_indices = pad_and_crop_to_maximum_length(input_indices, padding_value=pad_index, maximum_sequence_length=maximum_sequence_length)\n",
    "mask = pad_and_crop_to_maximum_length(mask, padding_value=1, maximum_sequence_length=maximum_sequence_length)\n",
    "masked_indices = pad_and_crop_to_maximum_length(masked_indices, padding_value=pad_index, maximum_sequence_length=maximum_sequence_length)\n",
    "labels = pad_and_crop_to_maximum_length(labels, padding_value=-100, maximum_sequence_length=maximum_sequence_length)\n",
    "\n",
    "print(\"After padding / cropping\")\n",
    "pc(\"Input indices\", input_indices)\n",
    "pc(\"Mask\", mask)\n",
    "pc(\"Masked indices\", masked_indices)\n",
    "pc(\"Labels\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af75aa-6e5e-427c-ad1a-e3585c980a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
